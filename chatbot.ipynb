{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED = \"\\033[1;31m\"\n",
    "GREEN = \"\\033[0;32m\"\n",
    "RESET = \"\\033[0;0m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Libería SBERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración del Log y Carga del Modelo\n",
    "\n",
    "Se configura el logging y se carga el modelo de SentenceTransformer. Esto permite registrar información útil mientras el bot está en funcionamiento y asegurar que el modelo se carga correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\picherks\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-14 16:30:44,430 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2024-04-14 16:30:44,441 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-04-14 16:30:44,822 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 200 0\n",
      "2024-04-14 16:30:44,948 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
      "2024-04-14 16:30:45,427 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1\" 200 0\n",
      "2024-04-14 16:30:45,534 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1\" 200 0\n",
      "2024-04-14 16:30:45,639 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1\" 200 0\n",
      "2024-04-14 16:30:45,737 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-04-14 16:30:47,277 - DEBUG - https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2024-04-14 16:30:47,545 - DEBUG - https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1\" 200 19916\n",
      "2024-04-14 16:30:47,568 - INFO - Use pytorch device_name: cpu\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load the SentenceTransformer model\n",
    "modelSBERT = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de Respuestas del Chatbot\n",
    "\n",
    "Se definen las respuestas posibles del chatbot. Estas respuestas serán utilizadas para entrenar el modelo y generar los embeddings correspondientes.\n",
    "\n",
    "#### **Propósito**\n",
    "En este caso es un chatbot para atención al cliente para una empresa de buses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's responses definition\n",
    "responses = [\n",
    "    \"You can buy tickets on our website or at the station.\",\n",
    "    \"The bus schedule is from 6 a.m. to 10 p.m.\",\n",
    "    \"The bus fare depends on your destination.\",\n",
    "    \"Our buses depart every 30 minutes.\",\n",
    "    \"You can cancel your ticket 24 hours before departure.\",\n",
    "    \"Please provide an ID document when purchasing your ticket.\",\n",
    "    \"Children under 5 years old travel for free.\",\n",
    "    \"You can bring up to two bags in the luggage compartment at no extra cost.\",\n",
    "    \"The buses are equipped with free Wi-Fi.\",\n",
    "    \"We have special services for people with disabilities.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversión de Respuestas en Embeddings\n",
    "\n",
    "Se convierten las respuestas en embeddings usando el modelo cargado. Estos embeddings se almacenan en un arreglo para su uso posterior durante la búsqueda de respuestas similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Conversion of responses to embeddings using the model\n",
    "response_embeddings_SBERT = modelSBERT.encode(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para Encontrar la Respuesta Más Similar\n",
    "\n",
    "Se implementa una función que convierte la pregunta del usuario en un embedding y compara este con los embeddings de las respuestas usando la similitud de coseno. La función devolverá la respuesta más similar si la similitud supera un umbral definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to find the most similar response\n",
    "def find_similar_response(question, threshold=0.5):\n",
    "    question_embedding = modelSBERT.encode([question])[0]\n",
    "    similarities = cosine_similarity([question_embedding], response_embeddings_SBERT)\n",
    "    logging.debug(f\"Similarities: {similarities}\")\n",
    "    similar_response_index = similarities.argmax()\n",
    "    max_similarity = similarities[0][similar_response_index]\n",
    "    logging.debug(f\"Most similar response index: {similar_response_index}, with similarity of: {RED}{max_similarity}\")\n",
    "    if max_similarity < threshold:\n",
    "        return \"I'm sorry, I don't understand your question. Can you rephrase it?\"\n",
    "    return responses[similar_response_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba del Chatbot\n",
    "\n",
    "Se prueba la función del chatbot con una pregunta de ejemplo para verificar que todo está funcionando correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "2024-04-14 16:30:48,274 - DEBUG - Similarities: [[0.4184351  0.48985595 0.7404922  0.41205186 0.3041825  0.45003402\n",
      "  0.32196605 0.2980988  0.45304674 0.15949886]]\n",
      "2024-04-14 16:30:48,276 - DEBUG - Most similar response index: 2, with similarity of: \u001b[1;31m0.7404922246932983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How much does the bus ticket cost?\n",
      "Answer: The bus fare depends on your destination.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s]\n",
      "2024-04-14 16:30:48,473 - DEBUG - Similarities: [[0.7051648  0.22318847 0.3142142  0.18687859 0.4629287  0.6089513\n",
      "  0.27267462 0.16547292 0.226758   0.1766938 ]]\n",
      "2024-04-14 16:30:48,474 - DEBUG - Most similar response index: 0, with similarity of: \u001b[1;31m0.7051647901535034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where can I buy a ticket?\n",
      "Answer: You can buy tickets on our website or at the station.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n",
      "2024-04-14 16:30:48,533 - DEBUG - Similarities: [[0.24244018 0.47238392 0.532012   0.44691795 0.18229948 0.16971964\n",
      "  0.18064415 0.13823308 0.6641406  0.13947774]]\n",
      "2024-04-14 16:30:48,534 - DEBUG - Most similar response index: 8, with similarity of: \u001b[1;31m0.6641405820846558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do the buses have internet connection?\n",
      "Answer: The buses are equipped with free Wi-Fi.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 22.22it/s]\n",
      "2024-04-14 16:30:48,587 - DEBUG - Similarities: [[0.17788033 0.42843872 0.53550875 0.44483542 0.1463207  0.21010485\n",
      "  0.3188027  0.15023677 0.5088656  0.55049133]]\n",
      "2024-04-14 16:30:48,588 - DEBUG - Most similar response index: 9, with similarity of: \u001b[1;31m0.5504913330078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are your buses inclusive for people with disabilities?\n",
      "Answer: We have special services for people with disabilities.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 26.31it/s]\n",
      "2024-04-14 16:30:48,633 - DEBUG - Similarities: [[ 0.00483785  0.01367205 -0.00110462  0.02725348  0.05284074  0.14165837\n",
      "   0.05424194 -0.0411313  -0.01045261  0.20565969]]\n",
      "2024-04-14 16:30:48,637 - DEBUG - Most similar response index: 9, with similarity of: \u001b[1;31m0.2056596875190735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: asdfasdf\n",
      "Answer: I'm sorry, I don't understand your question. Can you rephrase it?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing with multiple questions\n",
    "questionsFirstBot = [\n",
    "    \"How much does the bus ticket cost?\",\n",
    "    \"Where can I buy a ticket?\",\n",
    "    \"Do the buses have internet connection?\",\n",
    "    \"Are your buses inclusive for people with disabilities?\",\n",
    "    \"asdfasdf\"\n",
    "]\n",
    "\n",
    "# Loop through questions and get responses\n",
    "for question in questionsFirstBot:\n",
    "    response = find_similar_response(question)\n",
    "    print(\"Question:\", question)\n",
    "    print(\"Answer:\", response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Google API**\n",
    "Se introduce la API de Gemini de Google como una herramienta poderosa para la generación de contenido y la creación de embeddings. Esta API, parte de las herramientas de inteligencia generativa de Google, permite explorar y prototipar aplicaciones de AI generativa de manera accesible. En este ejemplo, se configura la API, se lista los modelos disponibles, y se procede a utilizar un modelo específico para la generación de embeddings de textos, lo que facilita tareas como la recuperación de documentos y la comparación de similitud semántica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 16:30:51,073 - DEBUG - Similarities: [[0.77064441 0.7874335  0.87427176 0.79279087 0.80261985 0.73916771\n",
      "  0.78858777 0.76667137 0.77922478 0.69734184]]\n",
      "2024-04-14 16:30:51,075 - DEBUG - Most similar response index: 2, with similarity of: \u001b[1;31m0.8742717645084002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How much does the bus ticket cost?\n",
      "Answer: The bus fare depends on your destination.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 16:30:51,326 - DEBUG - Similarities: [[0.8913632  0.79853758 0.79211193 0.80184422 0.84541858 0.88650367\n",
      "  0.83944273 0.78219161 0.75847285 0.77683351]]\n",
      "2024-04-14 16:30:51,327 - DEBUG - Most similar response index: 0, with similarity of: \u001b[1;31m0.8913632046458893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where can I buy a ticket?\n",
      "Answer: You can buy tickets on our website or at the station.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 16:30:51,570 - DEBUG - Similarities: [[0.74176042 0.78445277 0.81274167 0.79439202 0.7661319  0.71081177\n",
      "  0.75322246 0.74683511 0.88399265 0.720201  ]]\n",
      "2024-04-14 16:30:51,571 - DEBUG - Most similar response index: 8, with similarity of: \u001b[1;31m0.8839926494717021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do the buses have internet connection?\n",
      "Answer: The buses are equipped with free Wi-Fi.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 16:30:51,828 - DEBUG - Similarities: [[0.77961396 0.81527821 0.81800859 0.83126093 0.80214472 0.76347929\n",
      "  0.80039063 0.78495559 0.82528646 0.84328968]]\n",
      "2024-04-14 16:30:51,829 - DEBUG - Most similar response index: 9, with similarity of: \u001b[1;31m0.8432896768543996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are your buses inclusive for people with disabilities?\n",
      "Answer: We have special services for people with disabilities.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 16:30:52,083 - DEBUG - Similarities: [[0.75407702 0.77765883 0.77629029 0.76531303 0.7571019  0.79276084\n",
      "  0.79125123 0.72849478 0.75379476 0.77599439]]\n",
      "2024-04-14 16:30:52,084 - DEBUG - Most similar response index: 5, with similarity of: \u001b[1;31m0.7927608400393369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: asdfasdf\n",
      "Answer: I'm sorry, I don't understand your question. Can you rephrase it?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "# Configure API and model\n",
    "genai.configure(api_key='SECRET_KEY')\n",
    "model = 'models/embedding-001'\n",
    "\n",
    "\n",
    "\n",
    "# Convert responses to embeddings using the Gemini API\n",
    "response_embeddings = genai.embed_content(model=model,\n",
    "                                          content=responses,\n",
    "                                          task_type=\"retrieval_document\")\n",
    "\n",
    "# Define function to find the most similar response\n",
    "def find_similar_response_gemini(question, threshold=0.8):\n",
    "    global response_embeddings\n",
    "    question_embedding = genai.embed_content(model=model,\n",
    "                                             content=question,\n",
    "                                             task_type=\"retrieval_document\")\n",
    "\n",
    "    question_embeddingArray = np.array(question_embedding[\"embedding\"]).reshape(1, -1)\n",
    "    response_embeddingsArray = np.array(response_embeddings[\"embedding\"])\n",
    "\n",
    "    # Calculate cosine similarity between the question and each response in dictionary\n",
    "    similarities = cosine_similarity(question_embeddingArray, response_embeddingsArray)\n",
    "    logging.debug(f\"Similarities: {similarities}\")\n",
    "    similarities = similarities.flatten()  # Flatten the similarities array\n",
    "    \n",
    "    # Get the index of the most similar response\n",
    "    index = np.argmax(similarities)\n",
    "    logging.debug(f\"Most similar response index: {index}, with similarity of: {RED}{similarities[index]}\")\n",
    "    max_similarity = similarities[index]\n",
    "    # Check if the highest similarity score is below the threshold\n",
    "    if max_similarity < threshold:\n",
    "        return \"I'm sorry, I don't understand your question. Can you rephrase it?\"\n",
    "    \n",
    "    return responses[index]\n",
    "\n",
    "\n",
    "# Testing with multiple questions\n",
    "questions = [\n",
    "    \"How much does the bus ticket cost?\",\n",
    "    \"Where can I buy a ticket?\",\n",
    "    \"Do the buses have internet connection?\",\n",
    "    \"Are your buses inclusive for people with disabilities?\",\n",
    "    \"asdfasdf\"\n",
    "]\n",
    "\n",
    "# Loop through questions and get responses\n",
    "for question in questions:\n",
    "    response = find_similar_response_gemini(question)\n",
    "    print(\"Question:\", question)\n",
    "    print(\"Answer:\", response)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
